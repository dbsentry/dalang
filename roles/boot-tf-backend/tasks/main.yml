---
#############################################################################
#                       Confidentiality Information                         #
#                                                                           #
# This module is the confidential and proprietary information of            #
# DBSentry Corp.; it is not to be copied, reproduced, or transmitted in any #
# form, by any means, in whole or in part, nor is it to be used for any     #
# purpose other than that for which it is expressly provided without the    #
# written permission of DBSentry Corp.                                      #
#                                                                           #
# Copyright (c) 2020-2021 DBSentry Corp.  All Rights Reserved.              #
#                                                                           #
#############################################################################
## 1. Create encrypted S3 backend and Dynamodb table
## 2. Move tfstate to S3
## 3. Create a new S3 bucket and setup sync with S3 backend bucket
## 4. Create workspaces for each target environment
## 5. Create terraform role for each target environment
#############################################################################
- name: Set tf_bucket
  set_fact:
    tf_bucket: "{{ all_vars.tfstate_namespace + '-' + aws_account_name + '-' + all_vars.tfstate_name + '-state'}}"


- name: Check if S3 backend exists
  when: true
  community.aws.aws_s3_bucket_info:
    aws_access_key: "{{ aws_access_key_id }}"
    aws_secret_key: "{{ aws_secret_access_key }}"
  register: bucketlist

- name: Create S3 backend Block
  block:
    - name: S3 backend does not exist
      debug:
        msg: "S3 Backend does not exists. Creating one."
    - name: Create S3 bucket and DynamoDB Table
      when: true
      terraform:
        project_path: "{{ role_path }}/files/{{ aws_account_name }}"
        state: "{{ tf_target_state }}"
        force_init: true
        lock: yes
        variables:
          all_vars: "{{ all_vars | to_json }}"
          group_vars: "{{ group_vars | to_json }}"
          backend_vars: "{{ backend_vars | to_json }}"
      environment: 
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region }}"
    - name: Copy local backend to S3
      when: true
      shell: terraform init -force-copy
      args:
        chdir: "{{ role_path }}/files/{{ aws_account_name }}"
      environment: 
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region }}"
  when: ((tf_target_state in ["present","planned"]) and ((bucketlist.buckets | selectattr('name', 'equalto', tf_bucket) | list | length) == 0))

- name: Delete S3 backend Block
  block:
    - name: Check for backend.tf file
      when: true
      stat:
        path: "{{ role_path }}/files/{{ aws_account_name }}/backend.tf"
      register: tf_backend_file_data

    - name: Create backend.tf as it is absent
      copy:
        dest: "{{ role_path }}/files/{{ aws_account_name }}/backend.tf"
        content: | 
          terraform {
            required_version = ">= 0.12.2"

            backend "s3" {
              region         = "{{ aws_default_region }}"
              bucket         = "{{ tf_bucket }}"
              key            = "terraform.tfstate"
              dynamodb_table = "{{ tf_dynamodb_table }}"
              profile        = ""
              role_arn       = ""
              encrypt        = "true"
            }
          }
      when: not tf_backend_file_data.stat.exists

    - name: Modify S3 backend for deletion
      when: true
      terraform:
        project_path: "{{ role_path }}/files/{{ aws_account_name }}"
        state: "present"
        force_init: true
        lock: yes
        targets: ["module.terraform_state_backend"]
        variables:
          all_vars: "{{ all_vars | to_json }}"
          group_vars: "{{ group_vars | to_json }}"
          backend_vars: "{{ backend_vars | to_json }}"
      environment: 
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region }}"
    - name: Copy local backend to S3
      when: true
      shell: terraform init -force-copy
      args:
        chdir: "{{ role_path }}/files/{{ aws_account_name }}"
      environment: 
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region }}"
    - name: Delete S3 backend
      when: true
      terraform:
        project_path: "{{ role_path }}/files/{{ aws_account_name }}"
        state: "{{ tf_target_state }}"
        force_init: true
        lock: yes
        variables:
          all_vars: "{{ all_vars | to_json }}"
          group_vars: "{{ group_vars | to_json }}"
          backend_vars: "{{ backend_vars | to_json }}"
      environment: 
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region }}"
  when: ((tf_target_state in ["absent"]) and ((bucketlist.buckets | selectattr('name', 'equalto', tf_bucket) | list | length) == 1))


